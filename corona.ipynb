{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sJviRB4jodkV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eFqkVitVg82"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECvDrBueeu_8"
   },
   "source": [
    "> In this project, the model is designed for complex-valued video, you need to read the file and treat it as a complex-valued video, whether it is a complex-valued video or a real-valued video, and then store it as real-valued data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgqfW3VcVikS"
   },
   "source": [
    "> In the data folder, there are 9 MAT files, and each file has three 3D arrays of size (H,W,T<sub>total</sub>):\n",
    "> * D: raw data, original video\n",
    "> * L: low rank part, background\n",
    "> * S: sparse part, foreground\n",
    ">\n",
    "> where H is the height of the frame, W is the width of the frame, and T<sub>total</sub> is the total number of frames in the video. Also, the frame size has been resized to 100*100 (meaning H = W = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_T9MKyPVj2C"
   },
   "source": [
    "**Read files and Get data**\n",
    "\n",
    "Description: You already know the location of the files containing the videos, please read them and gather and organize the data.\n",
    "\n",
    "Requirements:\n",
    "1. You need to sample a continuous segment of length T (num_frames in the code) from the video every few frames (stride in the code), each segment of size (H,W,T)\n",
    "2. Because the model only accepts real-valued data, and the segment is complex-valued, it is necessary to concatenate the real and imaginary parts of the video along the third dimension.\n",
    " * Size changed from (H,W,T) to (H,W,T2), where T2 = T × 2, the first T 2D arrays are the real part of the segment, and the last T 2D arrays are the imaginary part of the segment\n",
    "3. Function I/O\n",
    " * Input: A MAT file, num_frames, stride\n",
    " * Output: D, L, S (the size should be (N,1,H,W,T2), where N is the number of segments of size (H,W,T2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fq1gY8bRVmOl"
   },
   "outputs": [],
   "source": [
    "def get_data(file, num_frames=40, stride=10):\n",
    "    data = loadmat(file, mat_dtype=True)\n",
    "    D, L, S = data[\"D\"], data[\"L\"], data[\"S\"]\n",
    "    D = D.astype(np.complex64)\n",
    "\n",
    "    segments = []\n",
    "    for i in range(0, D.shape[2] - num_frames + 1, stride):\n",
    "        segment_D = D[:, :, i:i + num_frames]\n",
    "        segment_L = L[:, :, i:i + num_frames]\n",
    "        segment_S = S[:, :, i:i + num_frames]\n",
    "        segments.append((segment_D, segment_L, segment_S))\n",
    "\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    segments_complex = segments.astype(np.complex64)\n",
    "    segments_real = np.real(segments_complex)\n",
    "    segments_imag = np.imag(segments_complex)\n",
    "    segments_concat = np.concatenate((segments_real, segments_imag), axis=-1)\n",
    "\n",
    "    return torch.from_numpy(np.expand_dims(segments_concat[:, 0], axis=1)), torch.from_numpy(np.expand_dims(segments_concat[:, 1], axis=1)), torch.from_numpy(np.expand_dims(segments_concat[:, 2], axis=1))\n",
    "# get_data('data/Board.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Khx0QN7Vq9T"
   },
   "source": [
    "**Building a custom dataset**\n",
    "\n",
    "Requirement:\n",
    "1. You now get D, L, S, build a custom dataset for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rChqoi3IVvfT"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, D, L, S, transform=None):\n",
    "        self.D, self.L, self.S = D, L, S\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.D)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.D[index],\n",
    "        y = (self.L[index], self.S[index])\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fNp3CEcsEJC"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iWlXTIrZ2Bd"
   },
   "source": [
    "> You'll be writing code for soft thresholding in your model, so here's a brief description of what soft thresholding is and how to use it\n",
    ">\n",
    "> * Hard thresholding will turn values close to 0 directly to 0, while soft thresholding will move all values closer to 0 (too close will directly become 0)\n",
    ">\n",
    "> * Using a soft threshold with $ℓ_1$-norm can make variables sparse, in practice you can often see many people use it because $ℓ_1$-norm has good properties (convex, continuous, sub-differentiable)\n",
    ">\n",
    "> * Suppose now you have a variable $x$ (scalar or vector) and a threshold $t \\geq 0$, you can do soft thresholding on $x$ as follows:\n",
    ">\n",
    ">  1. Change $x = ||x||_2 × \\frac{x}{||x||_2}$, the first part shows the magnitude and the second part shows the direction\n",
    ">  2. We do the thresholding on the magnitude, so change the magnitude to $\\text{ReLU}(||x||_2 - t)$\n",
    ">  3. The result $x'= \\text{ReLU}(||x||_2 - t) × \\frac{x}{||x||_2} = (||x||_2 - t)_{+} × \\frac{x}{||x||_2}$\n",
    "> * From the above example, you can find that the most important thing is to find an appropriate threshold $t$, which is what we want the model to learn\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMOPuD8VPNl9"
   },
   "source": [
    "**Complex Convolutional 3D Layer**\n",
    "\n",
    "From the equation:\n",
    "\n",
    "Y = X × W \\\n",
    "= Y<sub>real</sub> + jY<sub>imag</sub>\n",
    "= (X<sub>real</sub> + jX<sub>imag</sub>) × (W<sub>real</sub> + jW<sub>imag</sub>)\\\n",
    "= X<sub>real</sub> × W<sub>real</sub> + X<sub>real</sub> × jW<sub>imag</sub> + jXi × W<sub>real</sub> + jX<sub>imag</sub> × jW<sub>imag</sub> \\\n",
    "= (X<sub>real</sub> × W<sub>real</sub> - X<sub>imag</sub> × W<sub>imag</sub>) + j(X<sub>real</sub> × W<sub>imag</sub> + X<sub>imag</sub> × W<sub>real</sub>)\n",
    "\n",
    "We can easily find out how to directly use the real and imaginary parts of the input and weight to get the correct result Y<sub>real</sub>, Y<sub>imag</sub> (all are real-valued)\n",
    "\n",
    "Requirements:\n",
    "* Construct the Conv3dC class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mu2q1IWyPNQN"
   },
   "outputs": [],
   "source": [
    "class Conv3dC(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv3dC, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.convR = nn.Conv3d(1, 1, kernel_size=kernel_size, padding='same')  # W_real\n",
    "        self.convI = nn.Conv3d(1, 1, kernel_size=kernel_size, padding='same')  # W_imag\n",
    "\n",
    "    def forward(self, X):\n",
    "        T = X.shape[-1] // 2\n",
    "        R = X[..., :T]\n",
    "        I = X[..., T:]\n",
    "        Y = torch.concat([self.convR(R) - self.convI(I), self.convR(I) + self.convI(R)], dim=-1)\n",
    "        return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2avLScmbkTz7"
   },
   "source": [
    "**Combination of three Complex Convolutional 3D Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U_yFlym3rxkz"
   },
   "outputs": [],
   "source": [
    "class Conv3dCx3(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv3dCx3, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.convD = Conv3dC(kernel_size)\n",
    "        self.convL = Conv3dC(kernel_size)\n",
    "        self.convS = Conv3dC(kernel_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        D, L, S = X\n",
    "        D = self.convD(D)\n",
    "        L = self.convL(L)\n",
    "        S = self.convS(S)\n",
    "        return D + L + S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDMhUbR3kZMa"
   },
   "source": [
    "**Singular Value Thresholding (SVT)**\n",
    "\n",
    "Description:\n",
    "* SVT is used to make the matrix low rank, the principle is to make the singular value sparse\n",
    "* Learnable parameter: lambda_L\n",
    "* Threshold: sigmoid(lambda_L) × coeff_L × maximum singular value\n",
    "* Each segment (containing many frames) has a threshold\n",
    "* Reshape input of size (N,1,H,W,T2) to (N,1,H×W,T2) and convert it to a complex-valued version of size (N,1,H×W,T), and do sigular value thresholding for each sample of size (H×W,T)\n",
    "\n",
    "Requirements:\n",
    "* Please complete the forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y_yD0EiysKGC"
   },
   "outputs": [],
   "source": [
    "class SVT(nn.Module):\n",
    "    def __init__(self, coeff_L):\n",
    "        super(SVT, self).__init__()\n",
    "\n",
    "        self.coeff_L = coeff_L\n",
    "        self.lambda_L = nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        s = X.shape\n",
    "        X = X.reshape([s[0], s[1], s[2] * s[3], s[4]])\n",
    "        t = s[4] // 2\n",
    "        XC = torch.complex(X[..., :t], X[..., t:])\n",
    "\n",
    "        U, S, Vt = torch.linalg.svd(XC, full_matrices=False)\n",
    "        a = self.sigmoid(self.lambda_L) * self.coeff_L * S.max(dim=-1).values\n",
    "        S_tr = torch.diag_embed(self.relu(S - a.reshape([s[0], 1, 1]))).type(torch.complex64)\n",
    "\n",
    "        Y = U @ S_tr @ Vt\n",
    "        Y = torch.concat([Y.real, Y.imag], dim=-1).reshape(s)\n",
    "\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTZYIQkikmKU"
   },
   "source": [
    "**Soft Thresholding (SFT)**\n",
    "\n",
    "Description:\n",
    "* SFT is used to make the array sparse\n",
    "* Learnable parameter: lambda_S\n",
    "* Threshold: sigmoid(lambda_S) × coeff_S × (root) mean square of elements per frame\n",
    "* Each frame has a threshold\n",
    "\n",
    "Requirements:\n",
    "* Please complete the forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IOLdiIhbsOBx"
   },
   "outputs": [],
   "source": [
    "class SFT(nn.Module):\n",
    "    def __init__(self, coeff_S):\n",
    "        super(SFT, self).__init__()\n",
    "\n",
    "        self.coeff_S = coeff_S\n",
    "        self.lambda_S = nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        s = X.shape\n",
    "        X = X.reshape([s[0], s[1], s[2] * s[3], s[4]])\n",
    "        t = s[4] // 2\n",
    "        XC = torch.complex(X[..., :t], X[..., t:])\n",
    "\n",
    "        a = self.sigmoid(self.lambda_S) * self.coeff_S * torch.sqrt((XC ** 2).mean(dim=[-2, -1]))\n",
    "        tr = 1 - a / torch.linalg.norm(XC, 2, dim=[-2, -1])\n",
    "        Y = (self.relu(tr.real) + 1.j * self.relu(tr.imag)).reshape((s[0], s[1], 1, 1)) * XC\n",
    "        Y = torch.concat([Y.real, Y.imag], dim=-1).reshape(s)\n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSiTDzS5l4hC"
   },
   "source": [
    "**ISTA Cell**\n",
    "\n",
    "Requirements:\n",
    "* Combining modules from above, construct a full ISTA Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4D7eF2XHsUUi"
   },
   "outputs": [],
   "source": [
    "class ISTACell(nn.Module):\n",
    "    def __init__(self, kernel_size, coeff_L, coeff_S):\n",
    "        super(ISTACell, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.coeff_L = coeff_L\n",
    "        self.coeff_S = coeff_S\n",
    "\n",
    "        self.netL = nn.Sequential(Conv3dCx3(kernel_size), SVT(coeff_L))\n",
    "        self.netS = nn.Sequential(Conv3dCx3(kernel_size), SFT(coeff_S))\n",
    "\n",
    "    def forward(self, X):\n",
    "        D = X[0]\n",
    "        L = self.netL(X)\n",
    "        S = self.netS(X)\n",
    "\n",
    "        Y = torch.zeros(X.shape).to(X.device)\n",
    "        Y[0], Y[1], Y[2] = D, L, S\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJVjpmSrmG3J"
   },
   "source": [
    "**Deep Network: Convolutional rObust pRincipal cOmpoNent Analysis (CORONA)**\n",
    "\n",
    "Description:\n",
    "* kernel_list contains some integers, each integer k can be used to set the kernel_size = [k,k,1] of the corresponding layer\n",
    "\n",
    "Requirement:\n",
    "* Construct the CORONA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qePcOBxBsaD5"
   },
   "outputs": [],
   "source": [
    "class CORONA(nn.Module):\n",
    "    def __init__(self, kernel_list, coeff_L=0.4, coeff_S=1.8):\n",
    "        super(CORONA, self).__init__()\n",
    "        self.kernel_list = kernel_list\n",
    "        self.coeff_L = coeff_L\n",
    "        self.coeff_S = coeff_S\n",
    "\n",
    "        self.net = nn.Sequential(*[ISTACell(layer, self.coeff_L, self.coeff_S) for layer in kernel_list])\n",
    "\n",
    "    def forward(self, D):\n",
    "        X = torch.zeros([3] + list(D.shape)).to(D.device)\n",
    "        X[0] = D\n",
    "        X = self.net(X)\n",
    "        L, S = X[1], X[2]\n",
    "        return L, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDQf4kMzCie3"
   },
   "source": [
    "### Compute loss\n",
    "\n",
    "Input:\n",
    "* target = (target_L, target_S)\n",
    "\n",
    "Requirement:\n",
    "* Create a function which computes output of net on the given input and calculates loss value for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pwRySj-zCliH"
   },
   "outputs": [],
   "source": [
    "def get_loss(net, input_D, target, alpha=0.5):\n",
    "    output_L, output_S = net(input_D)\n",
    "    target_L, target_S = target\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    loss_L = criterion(output_L, target_L)\n",
    "    loss_S = criterion(output_S, target_S)\n",
    "    loss = alpha * loss_L + (1 - alpha) * loss_S\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6h0T52zXbA5"
   },
   "source": [
    "### Function for constructing videos\n",
    "\n",
    "Input:\n",
    "* images_array is of size (H,W,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7mUfAEMjjXro"
   },
   "outputs": [],
   "source": [
    "def array_to_gray_video(images_array, video_name, fps=30):\n",
    "    # Get the height and width of the video, assuming all frames have the same size\n",
    "    height, width = images_array.shape[0], images_array.shape[1]\n",
    "\n",
    "    # Set the video codec to mp4\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "    # Create a VideoWriter object, with parameters for the output file name, codec, frame rate, and size\n",
    "    video = cv2.VideoWriter(video_name, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    # Write each frame in the numpy array to the output video\n",
    "    for i in range(images_array.shape[2]):\n",
    "        image = images_array[:, :, i]\n",
    "        image = np.uint8(image)  # Convert to uint8 format\n",
    "        video.write(image)\n",
    "\n",
    "    # Release the resources used by the VideoWriter and destroy any OpenCV windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQVyhkAlWCOT"
   },
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNvwVd1mAZFR"
   },
   "source": [
    "Decide which device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jOqucvKo6O3A"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcH5PHFcJwzI"
   },
   "source": [
    "**Get data**\n",
    "\n",
    "Requirements:\n",
    "* Get data from the files and concatenate them\n",
    "* Build datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrqzVWd3WDY6",
    "outputId": "6d229432-2643-4173-9e68-24b02415a750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Board.mat', 'Candela_m1.mat', 'CAVIAR1.mat', 'CaVignal.mat', 'HallAndMonitor.mat', 'HighwayI.mat', 'HighwayII.mat', 'IBMtest2.mat', 'Snellen.mat']\n"
     ]
    }
   ],
   "source": [
    "path = 'data'\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)\n",
    "\n",
    "D_list, L_list, S_list = [], [], []\n",
    "for file in file_list:\n",
    "    Di, Li, Si = get_data(path + '/' + file)\n",
    "    D_list.append(Di)\n",
    "    L_list.append(Li)\n",
    "    S_list.append(Si)\n",
    "\n",
    "D, L, S = torch.cat(D_list, dim=0).to(device), torch.cat(L_list, dim=0).to(device), torch.cat(S_list, dim=0).to(device)\n",
    "\n",
    "data = CustomDataset(D, L, S)\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "valid_size = len(data) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(data, [train_size, valid_size])\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgQ45gWfL69h"
   },
   "source": [
    "Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WAtEDouWL7WB"
   },
   "outputs": [],
   "source": [
    "kernel_list = [5, 5, 5]\n",
    "coeff_L = 0.4\n",
    "coeff_S = 1.8\n",
    "net = CORONA(kernel_list, coeff_L=coeff_L, coeff_S=coeff_S)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm6QET0qMgso"
   },
   "source": [
    "**Train the model**\n",
    "\n",
    "Requirements:\n",
    "* Determine the optimizer\n",
    "* Finish the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "raFbk0juMjLX",
    "outputId": "a3ac7b0c-e609-43fb-cb5a-773e6bfc6ee1"
   },
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "alpha = 0.5\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=2e-3, params=net.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, 0.7)\n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for i, ([D], target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = get_loss(net, D, target, alpha)\n",
    "        train_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if i % 5 == 0:\n",
    "        #     print(f'{i}th batch')\n",
    "    train_loss /= train_size / batch_size\n",
    "    train_loss = train_loss.item()\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    for [D], target in valid_loader:\n",
    "        valid_loss += get_loss(net, D, target, alpha).detach()\n",
    "    valid_loss /= valid_size / batch_size\n",
    "    valid_loss = valid_loss.item()\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        net_best = net\n",
    "        min_valid_loss = valid_loss\n",
    "    \n",
    "        \n",
    "    scheduler.step()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Epoch {epoch} completed with {train_loss = } and {valid_loss = }')\n",
    "\n",
    "net = net_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjoH-wUYVIjX"
   },
   "source": [
    "**Save the model and the results**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder\n",
    "* Save the model (net) and results (training/validation loss list) to the folder\n",
    "\n",
    "Hint:\n",
    "* You can use 'Path().mkdir()' to create a folder\n",
    "* You can use 'torch.save' to save the model\n",
    "* You can use 'np.savez' to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KjQhHpSqVnLt"
   },
   "outputs": [],
   "source": [
    "model_folder = 'model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "model_path = model_folder + '/model_data.pth'\n",
    "\n",
    "torch.save(net.state_dict(), model_path)\n",
    "\n",
    "np.savez(model_folder + '/history.npz', train=train_loss_list, valid=valid_loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBSGS8qZ0wem"
   },
   "source": [
    "Uploading model for a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2dKv4Y70wEO",
    "outputId": "d9291181-9f2f-4ed6-d35c-7b6ee2da339e"
   },
   "outputs": [],
   "source": [
    "model = CORONA(kernel_list, coeff_L=coeff_L, coeff_S=coeff_S)\n",
    "model.load_state_dict(torch.load(model_folder+'/model_data.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fw5fiNvQVnyd"
   },
   "source": [
    "**Plot the figures**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder called 'fig_folder' and save the figure in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "HiU7cQiFVoQ9",
    "outputId": "17dc3e78-04e6-4cfc-b940-02164323cac5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_folder='fig_folder'\n",
    "os.makedirs(fig_folder, exist_ok=True)\n",
    "\n",
    "num_epochs = len(train_loss_list)\n",
    "x_range = np.arange(num_epochs) + 1\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_range, train_loss_list, label='Training')\n",
    "plt.plot(x_range, valid_loss_list, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch index')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.ylim((0, 1))\n",
    "\n",
    "plt.savefig(fig_folder + '/loss_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYerh6P9WrQU"
   },
   "source": [
    "**Get the videos**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder called 'pred_folder' and save the predictions in this folder\n",
    "* Create a folder called 'video_folder' and save the videos in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vAatYM2zWrmc",
    "outputId": "bd115ca2-f664-4c14-9b3d-4eb718b083ae"
   },
   "outputs": [],
   "source": [
    "#(?) Create 'pred_folder' and 'video_folder'\n",
    "\n",
    "video_folder='video_folder'\n",
    "os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "pred_folder='pred_folder'\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "\n",
    "data_dir = file_list[0]\n",
    "\n",
    "#\n",
    "num_frames = 40\n",
    "for file in file_list:\n",
    "    D = loadmat('data/' + file)['D']\n",
    "    D = torch.from_numpy(D).cfloat()\n",
    "    L = torch.empty(0)\n",
    "    S = torch.empty(0)\n",
    "    for k in range(0, D.shape[-1] - num_frames + 1, num_frames):\n",
    "        Dk = D[None, None, :, :, k:k + num_frames]\n",
    "        Dk = torch.cat([torch.real(Dk), torch.imag(Dk)], dim=-1)\n",
    "        Dk = Dk.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            Lk, Sk = net(Dk)\n",
    "\n",
    "        Lk = Lk[..., :num_frames].cpu().detach().squeeze()\n",
    "        Sk = Sk[..., :num_frames].cpu().detach().squeeze()\n",
    "\n",
    "        L = torch.cat([L, Lk], dim=-1)\n",
    "        S = torch.cat([S, Sk], dim=-1)\n",
    "\n",
    "    savemat('%s/prediction_%s' % (pred_folder, file), {'L': L.numpy(), 'S': S.numpy()})\n",
    "\n",
    "    D = torch.real(D[..., :L.shape[-1]])\n",
    "    V = np.round(torch.cat([D, L, S], dim=1).numpy() * 255)\n",
    "    array_to_gray_video(V, '%s/video_%s.mp4' % (video_folder, file[:-4]), fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
